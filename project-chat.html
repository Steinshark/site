<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-49NV8NMBJP"></script>
  <script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-49NV8NMBJP');
  </script>



  <link rel="stylesheet" href="styles.css" />
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Steinshark Language Model Project</title>
  <style>
    .hero {
      position: relative;
      text-align: center;
      background: url('https://images.unsplash.com/photo-1518770660439-4636190af475?auto=format&fit=crop&w=1350&q=80') center/cover no-repeat;
      height: 60vh;
      display: flex;
      flex-direction: column;
      justify-content: center;
      color: white;
      text-shadow: 0 2px 8px rgba(0, 0, 0, 0.6);
    }

    .hero h1 {
      font-size: 3rem;
      margin-bottom: 0.5rem;
    }

    .hero p {
      font-size: 1.25rem;
    }

    .image-box {
    display: inline-block;
    padding: 6px;
    border: 2px solid #ccc;
    border-radius: 12px;
    background-color: #f9f9f9;
    box-shadow: 2px 2px 8px rgba(0, 0, 0, 0.1);
    width: fit-content;
    }

    .image-box img {
    border-radius: 8px;
    display: block;
    max-width: 100%;
    height: auto;
    }
    .model-architecture {
        display: flex;
        flex-direction: column;
        align-items: center;
        margin: 2rem 0;
        /* border: 2px solid #ccc;
        border-radius: 12px; */

    }

    .model-block {
        background: #f8f9fa;
        border: 2px solid #ccc;
        border-radius: 12px;
        padding: 1rem 1.5rem;
        margin: 0.5rem 0;
        font-weight: bold;
        width: 80%;
        max-width: 500px;
        text-align: center;
        box-shadow: 2px 2px 6px rgba(0,0,0,0.1);
    }

    .arrow {
        font-size: 2.5rem;
        color: #777;
        margin: 0.25rem 0;
    }

    .embedding-matrix {
        padding: 1rem;
        background-color: #e0f7fa;
        border: 2px solid #4dd0e1;
        border-radius: 16px;
        box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.1);
        width: fit-content;
        margin: 1rem auto;
    }

    .embedding-title {
        font-size: 1rem;
        font-weight: bold;
        margin-bottom: 0.75rem;
        text-align: center;
        color: #007c91;
    }

    .embedding-grid {
        display: grid;
        grid-template-columns: repeat(16, 1fr); /* n = 16 columns */
        gap: 4px;
    }

    .embedding-grid-T {
        display: grid;
        grid-template-columns: repeat(3, 1fr); /* n = 16 columns */
        gap: 4px;
    }

    .embedding-cell {
        width: 16px;
        height: 16px;
        background-color: #4dd0e1;
        border-radius: 4px;
    }

    .decoder-layer {
        background-color: #f3f4f6;
        border: 2px solid #cbd5e0;
        border-radius: 16px;
        padding: 1rem;
        width: fit-content;
        margin: 2rem auto;
        box-shadow: 2px 2px 8px rgba(0, 0, 0, 0.1);
        font-family: sans-serif;
    }

    .layer-title {
      text-align: center;
      font-weight: bold;
      font-size: .9rem;
      margin-bottom: 1rem;
      color: #2c5282;
    }

    .layer-block {
      background-color: #e2e8f0;
      padding: 0.2rem 1rem;
      border-radius: 8px;
      margin: 0.2rem 0;
      text-align: center;
      font-size: 0.7rem;
      color: #1a202c;
    }

    .layer-block.residual {
      background-color: #c6f6d5;
      font-weight: bold;
      border: 1px dashed #38a169;
    }

    .transformer-stack {
      border: 3px solid #81e6d9;
      background-color: #e0f7fa;
      border-radius: 20px;
      padding: 1rem;
      margin: 2rem auto;
      box-shadow: 0px 0px 12px rgba(0, 0, 0, 0.1);
    }

    .stack-title {
      text-align: center;
      font-size: 1rem;
      font-weight: bold;
      margin-bottom: 1.5rem;
      color: #007c91;
    }

    .model-container {
      position: relative;
      border: 2px solid #4dd0e1;
      border-radius: 16px;
      padding: 2rem 1rem 1rem 1rem;
      background-color: transparent;
      margin: 2rem auto;
      width: fit-content;
      box-shadow: 3px 3px 10px rgba(0,0,0,0.1);

      display: flex;              /* makes children layout horizontally */
      flex-direction: row;        /* horizontal direction */
      align-items: center;        /* vertical alignment center */
      gap: 1.5rem;                /* spacing between items */
    }

    .model-label {
      position: absolute;
      top: -1rem;   /* moves label above the box */
      left: 1rem;   /* align with box padding */
      background-color: white; /* or match your page background */
      padding: 0 0.5rem;
      font-weight: bold;
      color: #4dd0e1;
      font-size: 1.1rem;
      border-radius: 8px;
      box-shadow: 0 0 5px rgba(77, 208, 225, 0.7);
    }
    .two-column {
      display: flex;
      flex-wrap: wrap;
      gap: 2rem;
      align-items: flex-start;
      margin: 2rem 0;
    }

    .column-text, .column-image {
      flex: 1 1 45%;
    }

    .column-text {
      font-size: 1rem;
      line-height: 1.6;
    }

    .column-image img {
      width: 100%;
      height: auto;
      border-radius: 12px;
      border: 1px solid #ccc;
      box-shadow: 2px 2px 10px rgba(0,0,0,0.1);
    }

    .image-caption {
      font-size: 0.9rem;
      color: #666;
      margin-top: 0.5rem;
      text-align: center;
    }
    
    .param-box {
      border: 2px solid #4dd0e1;
      background-color: #e0f7fa;
      border-radius: 16px;
      padding: 1rem 1.5rem;
      width: fit-content;
      margin: 1rem auto;
      box-shadow: 3px 3px 10px rgba(0,0,0,0.1);
    }

    .param-title {
      font-size: 1.2rem;
      font-weight: bold;
      margin-bottom: 0.75rem;
      text-align: center;
      color: #007c91;
    }

    .param-grid {
      display: grid;
      grid-template-columns: auto auto auto auto; /* Two key-value pairs per row */
      gap: 0.5rem 1.5rem;
    }

    .param-key {
      font-weight: 600;
      color: #1565c0;
      white-space: nowrap;
    }

    .param-value {
      font-family: monospace;
      color: #1e88e5;
    }
  </style>
</head>
<body>
  <header>
    <div><strong>SLM Project</strong></div>
    <nav>
      <a href="./index.html">Home</a>
      <a href="./story.html">Story</a>
      <a href="./projects.html">Projects</a>
      <a href="./chat.html">Chat</a>
    </nav>
    <div class="code-stream"></div>
  </header>

  <div class="hero">
    <h1>Welcome to the SLM Project</h1>
    <p>My Finest Language Model Yet</p>
  </div>

  <div class="content">
    <h2>Intro</h2>
    <p>
      Anyone remember <a href="https://www.cleverbot.com/?say=Steinshark sent me!" target="_blank" rel="noopener noreferrer">Cleverbot</a>? For a lot of us, this was our first intro to semi-intelligent autonomous chatting. 
      Now I know the inner-workings behind it are nothing like an LLM - but it was an intriguing experience to engage with a non-human agent. 
      That fascination persisted, and after I saw a few classmates playing with <a href="https://en.wikipedia.org/wiki/GPT-1" target="_blank" rel="noopener noreferrer">GPT-1</a> for their NLP class, I was hooked on the idea of making my own.  
    </p>
    <p>
      At this point, no novel idea of mine will have the compute behind it to make the next ChatGPT, but I'd like to have some fun along the way and make something of substance at the very least. Enter SLM - the Steinshark Language Model. 
    </p>

    <div class="image-box">
        <img src="images/datacenter-thin.jpg" alt="Project Preview">
    </div>

    <h2>Phase 1 - Curate the Data</h2>
    <p>
      Data is a lucrative field these days. To be sure, there is plenty of free data out there. The <a href="https://commoncrawl.org/" target="_blank" rel="noopener noreferrer">Common Crawl</a> is the entire internet - for free. 
      They even cleaned up the html to give you the text underneath! But the problem with this data is noise. And there is plenty of noise on the internet... 
      High quality data is what we're really searching for. And to train a decent model, we need a lot of it. 
    </p>

    <p>
      GPT-1, for starters, was trained on 4.7GB of data - around 1 billion words. That much text would take 11 years for the average Joe to read. And GPT-1 was just a toy model at best.
      GPT-2 upped the game to 40GB of text, this time from <a href="https://www.reddit.com/r/rickroll/" target="_blank" rel="noopener noreferrer">Reddit Posts</a>.
      The first recognizably modern model, GPT-3, brought this up to 570GB, 300B tokens, or around 15,000,000 man-hours of reading. 
    </p>

    <p>
        With this type of scaling in mind, the search for a metric heck ton of data commenced. A balance of quantity and quality was needed, and so I hit the books (spoken the internet). So, how did I tackle this? Lets find out...
    </p>

    <div class="two-column">
        <div class="column-text">
            <p>
                Free, big, easy, and clean is the "choose only 3" setup for data. At first, I left out fast. Weeks were spent downloading Common Crawl pages, adjusting my filter, finding something I missed, and reapeating.
                Eventually, I gave up on the autonomy and went crawling to <a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb" target="_blank" rel="noopener noreferrer">FineWeb</a>, 
                a wonderful collection of highly curated English language web pages that did a better job than I ever could at filtering. 
                For training I grabbed a 250GB subset of the 51.3TB available and got to work.
            </p>

            <p>
                Copy-pasting a dataset just didn't fit the vibe of this project,so I went ahead and filtered it further. I took out adult, ad and spam content, filtered short articles, and tossed out anything with a language score of under .95 (<a href='https://huggingface.co/facebook/fasttext-language-identification' target="_blank" rel="noopener no referrer">fasttext</a> classifier score). This chopped the data down to 88GB. 
                Next, I curated a huge list of whitelist phrases, topics, and genres to include in the final dataset. This led to a massive reduction, around 15-20% of the first pass text. I sprinkled in some curated <a href="https://data.stackexchange.com/stackoverflow/query/new" target="_blank" rel="noopener noreferrer">StackOverflow</a> posts, <a href="https://www.gutenberg.org/" target="_blank" rel="noopener noreferrer">Project Gutenberg</a> selections, and <a href="https://github.com/chris-lovejoy/youtube-titles-and-transcripts?tab=readme-ov-file" target="_blank" rel="noopener noreferrer">YouTube Transcripts</a>.
            </p>
        </div>
        
        <div class="column-image">
            <img src="images/webstats.jpeg" alt="Infographic showing internet data usage" />
            <p class="image-caption">Over 500,000 GB of data is created online every minute.</p>
        </div>
    </div>

    <p>
        The key here is that every bit of noise we take out programmatically is noise the model doesn't have to waste parameters on to filter out. Was the weeks-long data curation process worth it? Who knows! 
        Lesson learned about pre-mature optimization, I guess. 
    </p>

    <div class="model-container">
        <div class="model-label">Data Pipeline</div>
            <div class="embedding-matrix">
                <div class="embedding-title">FineWeb (250GB)</div>
            </div>

       
            <div class="arrow">&#8594;</div>
        
            <div class="embedding-matrix">
                <div class="embedding-title">Remove Bad Content (109GB)</div>
            </div>

            <div class="arrow">&#8594;</div>
            
            <div class="embedding-matrix">
                <div class="embedding-title">Select Good Content (31.1GB)</div>
            </div>

            <div class="arrow">&#8594;</div>

            <div class="embedding-matrix">
                <div class="embedding-title">Tokenize to 32k Vocab Words</div>
            </div>

            <div class="arrow">&#8594;</div>

            <div class="model-container">
                <div class="model-label">Final Set</div>
    
                    <div class="embedding-matrix">
                        <div class="embedding-title">7.2B tokens</div>
                    </div>
        
            </div>

    </div>


    <h2>Phase 2 - Design an Architecture</h2>
    <p>
      Pytorch is a very familiar framework to me at this point. Countless hours have been spent building everything from <a href="https://github.com/Steinshark/chess" target="_blank" rel="noopener noreferrer">Chess Engines</a> to <a href="https://github.com/Steinshark/ReinforcementLearning" target="_blank" rel="noopener noreferrer">RL Snake-Playing agents</a>. 
      The transformer architecture was a new one to me, though. I remember distinctly one morning on vacation sitting in the Aqua Aloha Surf hotel in Honolulu, non-chalantly parsing over <a href="https://arxiv.org/abs/1706.03762">Attention is All You Need</a> - as one does. 
      Thus began my deep dive into transformer-based langauge models.
    </p>

    <p>
      To understand the transformer mechanism, field advancements (RoPE, data/computation/training optimizations, etc...), and exactly what I could do with it took more time. 
      Given my hardware limitations (RTX 4060Ti 16GB), I took to &le;1B parameter models. 
      Months of toying around and optimizing compute, memory, and data requirments led me to the following model training as we speak:   
    </p>

    <div class="model-container">
        <div class="model-label">Steinshark LM</div>
            <div class="embedding-matrix">
                <div class="embedding-title">Embedding Layer (<span id="n-vocab1"></span> x <span id="n-embed1"></span>)</div>
                <div class="embedding-grid">
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                </div>
            </div>

       
            <div class="arrow">&#8594;</div>
        
            <div class="transformer-stack">
                <div class="stack-title">Stacked Transformer Decoder (<span id="n-layers1"></span>)</div>

                <!-- Repeat this block 16 times for each decoder layer -->
                <div class="decoder-layer">
                    <div class="layer-title">Decoder Layer</div>
                    <div class="layer-block">LayerNorm</div>
                    <div class="layer-block">Multi-Head Attention</div>
                    <div class="layer-block">Dropout</div>
                    <div class="layer-block residual">+ Residual</div>
                    <div class="layer-block">LayerNorm</div>
                    <div class="layer-block">Feedforward</div>
                    <div class="layer-block">Dropout</div>
                    <div class="layer-block residual">+ Residual</div>
                </div>

                <!-- Add more decoder-layer blocks as needed -->
            </div>

            <div class="arrow">&#8594;</div>
            
            <div class="embedding-matrix">
                <div class="embedding-title">LM Head</div>
                <div class="embedding-grid-T">
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                    <div class="embedding-cell"></div>
                </div>
            </div>

    </div>

    <div class="param-box">
    <h3 class="param-title">Model Parameters - <span id="param-count1"></span></h3>
    <div class="param-grid">

        <div class="param-key">Vocab Size:</div>
        <div class="param-value"><span id="n-vocab2"></span></div>

        <div class="param-key">Number heads:</div>
        <div class="param-value"><span id="n-heads1"></span></div>

        <div class="param-key">Embed Dims:</div>
        <div class="param-value"><span id="n-embed2"></span></div>

        <div class="param-key">Num Layers:</div>
        <div class="param-value"><span id="n-layers2"></span></div>

        <div class="param-key">FF Size:</div>
        <div class="param-value"><span id="n-ff1"></span></div>

        <div class="param-key">Context Len:</div>
        <div class="param-value"><span id="n-context1"></span></div>
    </div>
    
</div>


    <p>
      With this model we're off to the races! With the LM head weight-sharing with the embeddings, we are down to <span id="param-count2"></span> parameters. RoPE embeddings are nice to have (no position embeddings needed), and a head dimension of <span id="n-embed-head1"></span> makes for quick but effective training. Not big, but definitely capable of something! </p>
    </p>

    <h2>Check Back in Tomorrow for More!</h2>
    <p>
      Updates daily on the project! I code as much as I can after work (well into the night, its unhealthy...) to get updates to you. Thanks for reading so far!
    </p>
  
  </div>
  <script src="codeflow.js"></script>

  <script>
    const root = document.documentElement;
    document.getElementById('param-count1').textContent = getComputedStyle(root).getPropertyValue('--model-param-count').trim();
    document.getElementById('param-count2').textContent = getComputedStyle(root).getPropertyValue('--model-param-count').trim();
    document.getElementById('n-layers1').textContent = getComputedStyle(root).getPropertyValue('--model-n-layers').trim();
    document.getElementById('n-layers2').textContent = getComputedStyle(root).getPropertyValue('--model-n-layers').trim();
    document.getElementById('n-heads1').textContent = getComputedStyle(root).getPropertyValue('--model-n-heads').trim();
    document.getElementById('n-embed-head1').textContent = getComputedStyle(root).getPropertyValue('--model-n-embed-head').trim();
    document.getElementById('n-embed1').textContent = getComputedStyle(root).getPropertyValue('--model-n-embed').trim();
    document.getElementById('n-embed2').textContent = getComputedStyle(root).getPropertyValue('--model-n-embed').trim();
    document.getElementById('n-ff1').textContent = getComputedStyle(root).getPropertyValue('--model-n-ff').trim();
    document.getElementById('n-context1').textContent = getComputedStyle(root).getPropertyValue('--model-n-context').trim();
    document.getElementById('n-vocab1').textContent = getComputedStyle(root).getPropertyValue('--model-n-vocab').trim();
    document.getElementById('n-vocab2').textContent = getComputedStyle(root).getPropertyValue('--model-n-vocab').trim();
  </script>
</body>
</html>
